# MovieLens ETL Process

## Описание

Этот скрипт выполняет процесс ETL (Extract, Transform, Load) для данных из набора MovieLens. Скрипт читает данные из CSV-файлов, выполняет агрегирование и фильтрацию данных, а затем сохраняет результаты в формате JSON и CSV.

## Архитектура

Процесс разделен на три этапа:

1. **Extract**: Извлечение данных из CSV-файлов.
2. **Transform**: Трансформация данных, включая фильтрацию фильмов по жанру и подсчет распределения оценок для конкретного фильма.
3. **Load**: Загрузка данных в JSON и CSV файлы.

## Файлы на входе

- `ratings.csv`: содержит данные об оценках фильмов.
- `movies.csv`: содержит информацию о фильмах.
- `links.csv`: содержит ссылки на внешние базы данных для каждого фильма.

## Файлы на выходе

- `ratings_hist.json`: JSON-файл с распределением оценок для конкретного фильма и всех фильмов.
- `genre_movies.csv`: CSV-файл с фильмами, отфильтрованными по жанру, с полями `title`, `imdbId`, и `tmdbId`.

## Использование

### Установка

1. Клонируйте репозиторий:
    ```bash
    git clone https://github.com/ieromi/spark-movielens.git
    cd spark-movielens
    ```

2. Установите необходимые зависимости:
    ```bash
    pip install -r requirements.txt
    ```
3. Скачайте данные для анализа и распакуйте архив в директорию проекта:
    ```bash
    curl -O https://files.grouplens.org/datasets/movielens/ml-32m.zip && unzip ml-32m.zip
    ```

### Запуск

1. Запустите скрипт:
    ```bash
    python main.py
    ```

2. После выполнения скрипта в каталоге `output` будут созданы файлы `ratings_hist.json` и `genre_movies.csv`.

### Настройка

В скрипте можно изменить следующие параметры:

- Пути к входным файлам (`ratings.csv`, `movies.csv`, `links.csv`).
- Каталог для сохранения выходных данных (`output`).
- ID фильма для агрегации данных.
- Жанр для фильтрации фильмов.

## Логирование

Все операции в процессе ETL логируются в файл `etl_process.log`. В случае возникновения ошибок они также будут записаны в этот файл.

## Примечания

- При работе с PySpark на Windows необходимо убедиться, что установлен `winutils.exe` и правильно настроены переменные среды `HADOOP_HOME` и `hadoop.home.dir`.
- Если столкнулись с ошибкой при сохранении файла в формате CSV через PySpark, используйте Pandas как временное решение.
